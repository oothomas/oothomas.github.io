- title: "SlicerMorph Photogrammetry: SAM‑NodeODM Pipeline for High‑Fidelity 3D Specimens"
  description: >
    This project delivers a fully open, end‑to‑end photogrammetry workflow inside 3D Slicer that
    integrates automatic image masking via the Segment Anything Model (SAM) with surface reconstruction
    using OpenDroneMap’s NodeODM, wrapped in a user‑friendly Slicer extension. The module unifies image
    import, batch/single‑image masking, optional scaling via ArUco/GCPs, reconstruction, and direct model
    import for morphometric analysis.

    Goals were twofold: streamline background removal and improve geometric accuracy, especially around
    delicate cranial structures. Using 14 mountain‑beaver skulls with micro‑CT as reference, the updated
    workflow lowered mean surface distance and RMSE by ~10–15% across specimens versus our prior open‑source
    pipeline, while Hausdorff changed little—evidence that gains were global rather than driven by a few
    outliers. Qualitatively, thin elements (e.g., zygomatic arches, orbital rims) showed fewer breaks,
    clogs, and smoothing artifacts. A Taguchi L16 design efficiently explored NodeODM parameters
    (e.g., mesh‑octree‑depth, mesh‑size, feature/pc quality), yielding a reproducible configuration that
    balances fidelity and runtime; all job configs are saved as JSON for auditability.

    Findings: (1) Automated SAM masking markedly reduces manual cleanup and operator bias;
    (2) tuned NodeODM reconstruction produces smoother, more anatomically faithful meshes; and
    (3) the one‑ecosystem approach (mask → reconstruct → analyze) accelerates research hand‑offs to
    SlicerMorph morphometrics. Broader impact spans natural‑history collections, ecology/evolution studies,
    teaching/outreach, and large‑cohort digitization where cost, licensing, and throughput matter. Cloud‑ready
    deployment (MorphoCloud) supports GPU‑accelerated processing without local DevOps overhead.
  # Optional quick-link buttons (show as buttons if present)
  paper_url: "https://doi.org/10.1242/bio.062126"
  repo_url:  "https://github.com/SlicerMorph/SlicerPhotogrammetry"
  demo_url:  "https://github.com/SlicerMorph/SlicerPhotogrammetry"   # optional

  # Optional full citation string (shown under buttons)
  publication: "Thomas, O. O., Zhang, C., & Maga, A. M. (2025). SlicerMorph photogrammetry: An open‑source photogrammetry workflow for reconstructing 3D models. *Biology Open, 14*, bio062126. https://doi.org/10.1242/bio.062126"

  images:
    - thumb: "assets/images/projects/slicerphotogrammetry-ui-thumb.png"
      full:  "assets/images/projects/slicerphotogrammetry-ui-full.png"
      caption: "Workflow & UI: SAM-based batch masking and NodeODM reconstruction inside 3D Slicer, with the reconstructed textured skull imported directly for analysis."
      alt: "Functional-map pipeline diagram"  # optional
    - thumb: "assets/images/projects/slicerphotogrammetry-compare-thumb.png"
      full:  "assets/images/projects/slicerphotogrammetry-compare-full.png"
      caption: "Side‑by‑side reconstructions with deviation heatmaps versus micro‑CT; the updated pipeline reduces artifacts around thin structures (e.g., zygomatic arches) and lowers mean/RMSE errors."

- title: "AutoLandmark‑FM: Functional‑Map Landmarking for Mouse Mandibles"
  description: >
    This project develops an automated pipeline for anatomical landmark placement on 3D mouse
    hemi‑mandibles using descriptor learning and the functional map (FMap) framework. Instead of
    supervising to landmarks, the model learns intrinsic shape descriptors and dense functional
    correspondences in an unsupervised fashion, then recovers point‑to‑point maps to transfer
    landmarks across specimens. The workflow removes the need for rigid pre‑alignment and targets
    speed, accuracy, and generalizability.

    Methodologically, three upgrades over prior morphVQ are key: (1) orientation‑preserving Complex
    FMaps to avoid symmetry flips and eliminate pre‑alignment; (2) DiffusionNet for robust per‑vertex
    descriptors across mesh resolutions and surface complexities; and (3) spatial + spectral cycle
    consistency during Deep Functional Maps (DFMaps) training to enforce near‑bijective mappings and
    reduce post‑hoc refinement. Training is pairwise on meshes (LBO basis, WKS inputs), and dense
    correspondences are converted to landmark estimates via nearest‑neighbor transfer, aggregated with
    median selection for stability.

    Findings on a 425‑specimen mandible dataset show that the approach is faster than MALPACA while
    maintaining competitive accuracy. Although MALPACA often yields the lowest RMSE, AutoLandmark‑FM
    performs comparably—especially with smaller training sets—indicating strong generalization and
    practical viability. Visual checks confirm that automated placements typically fall within the
    acceptable range observed for MALPACA estimates.

    By combining unsupervised descriptor learning with functional correspondences, the
    pipeline scales landmarking to large cohorts, reduces manual effort, and flexibly adapts as
    hypotheses change (no re‑digitizing required). The result is a reproducible, high‑throughput
    alternative for morphometrics that plays nicely with open‑source tooling (e.g., 3D Slicer/SlicerMorph)
    and downstream statistical or ML analyses.

  # Optional quick-link buttons (show as buttons if present)
  paper_url: "https://onlinelibrary.wiley.com/doi/10.1111/joa.14196"
  repo_url:  "https://github.com/oothomas/SSC-MorphVQ"
  demo_url:  "https://github.com/oothomas/SSC-MorphVQ"   # optional

  # Optional full citation string (shown under buttons)
  publication: "Thomas, O. O., & Maga, A. M. (2025). Leveraging descriptor learning and functional map‑based shape matching for automated anatomical landmarking in mouse mandibles. *Journal of Anatomy, 246*, 829–845. https://doi.org/10.1111/joa.14196"

  images:
    - thumb: "assets/images/projects/autolandmarkfm-arch-thumb.png"
      full:  "assets/images/projects/autolandmarkfm-arch-full.png"
      caption: "Network and training scheme: DiffusionNet descriptor learning, main and complex functional map branches, and cycle‑consistency enforcing near‑bijective correspondences for landmark transfer."
      alt: "Functional-map pipeline diagram"  # optional
    - thumb: "assets/images/projects/autolandmarkfm-landmarks-thumb.png"
      full:  "assets/images/projects/autolandmarkfm-landmarks-full.png"
      caption: "FMAP's estimates (green) closely align with both MALPACA's (red) and the ground truth (blue), with deviations within expected human error. The model effectively estimates landmarks on 3D anatomical structures, advancing morphometric analysis by integrating geometry processing and deep-learning techniques."

- title: "morphVQ: Functional-Map Morphometrics for Automated Phenotyping"
  description: >
    morphVQ replaces manual landmarking with learned surface descriptors and functional maps to quantify
    whole‑mesh shape variation with minimal observer bias. After light rigid alignment, the pipeline learns
    dense non‑rigid correspondences between specimens and refines them with Consistent ZoomOut, producing
    two interpretable latent operators—area‑based and conformal (angular) latent shape‑space differences
    (LSSDs). These capture surface‑wide expansions, contractions, and angular changes that drive biological
    variation.
    In head‑to‑head comparisons, LSSDs match or exceed modern 3DGM and auto3DGM on downstream tasks
    (e.g., Genus‑level classification), while being more computationally efficient and preserving far more of
    the true surface morphology. Shape spaces derived from morphVQ closely mirror expert landmark pipelines,
    and distinctiveness functions localize which anatomical regions separate groups—turning correspondences
    into spatially grounded evidence.

  # Optional quick-link buttons (show as buttons if present)
  paper_url: "https://doi.org/10.1371/journal.pcbi.1009061"
  repo_url:  "https://github.com/oothomas/morphVQ"
  demo_url:  "https://github.com/oothomas/morphVQ"   # optional

  # Optional full citation string (shown under buttons)
  publication: "Thomas, O. O., Shen, H., Raaum, R. L., Harcourt-Smith, W. E. H., Polk, J. D., & Hasegawa-Johnson, M. (2023). Automated morphological phenotyping using learned shape descriptors and functional maps: A novel approach to geometric morphometrics. *PLOS Computational Biology, 19*(1), e1009061. https://doi.org/10.1371/journal.pcbi.1009061"

  images:
    - thumb: "assets/images/projects/morphvq-pipeline-thumb.png"
      full:  "assets/images/projects/morphvq-pipeline-full.png"
      caption: "Pipeline overview: manual GM vs. auto3DGM vs. morphVQ with learned descriptors, functional maps, Consistent ZoomOut, and LSSDs (area‑based & conformal)."
      alt: "Functional-map pipeline diagram"  # optional
    - thumb: "assets/images/projects/morphvq-distinctiveness-thumb.png"
      full:  "assets/images/projects/morphvq-distinctiveness-full.png"
      caption: "LSSD‑derived distinctiveness maps highlighting surface regions that most separate biological groups; warmer colors indicate stronger discriminative signal."
