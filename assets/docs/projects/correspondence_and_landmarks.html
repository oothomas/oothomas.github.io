<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Mesh Correspondence and Landmarks</title>
  <style>
    body {
      margin: 0;
      padding: 0;
      display: flex;
      flex-direction: row;
    }
    #view1, #view2 {
      width: 50%;
      height: 100vh;
      overflow: hidden;
      position: relative;
    }
  </style>

  <!-- Load vtk.js as a single bundled script (UMD). 
       No "dist/esm" or "Sources" needed. -->
  <script src="https://unpkg.com/vtk.js"></script>
</head>
<body>
  <!-- Two containers for side-by-side rendering -->
  <div id="view1"></div>
  <div id="view2"></div>

  <script>
    console.log("==== Starting correspondence_and_landmarks script ====");

    // ----------------------------------------------------------
    // 1) Create two side-by-side render windows
    // ----------------------------------------------------------
    console.log("Creating side-by-side VTK render windows...");
    const fullScreenRenderWindow1 = vtk.Rendering.Misc.vtkFullScreenRenderWindow.newInstance({
      rootContainer: document.getElementById('view1'),
      background: [0.2, 0.2, 0.2],
    });
    const renderer1 = fullScreenRenderWindow1.getRenderer();
    const renderWindow1 = fullScreenRenderWindow1.getRenderWindow();

    const fullScreenRenderWindow2 = vtk.Rendering.Misc.vtkFullScreenRenderWindow.newInstance({
      rootContainer: document.getElementById('view2'),
      background: [0.2, 0.2, 0.2],
    });
    const renderer2 = fullScreenRenderWindow2.getRenderer();
    const renderWindow2 = fullScreenRenderWindow2.getRenderWindow();

    // ----------------------------------------------------------
    // 2) Share the camera between both renderers
    // ----------------------------------------------------------
    console.log("Sharing camera...");
    const camera = renderer1.getActiveCamera();
    renderer2.setActiveCamera(camera);

    // When either interactor animates the camera, re-render both
    const updateBoth = () => {
      renderWindow1.render();
      renderWindow2.render();
    };
    renderWindow1.getInteractor().onAnimation(updateBoth);
    renderWindow1.getInteractor().onEndAnimation(updateBoth);
    renderWindow2.getInteractor().onAnimation(updateBoth);
    renderWindow2.getInteractor().onEndAnimation(updateBoth);

    // ----------------------------------------------------------
    // 3) Optional orientation marker in view1
    // ----------------------------------------------------------
    console.log("Setting up orientation marker...");
    const axesActor = vtk.Rendering.Core.vtkAxesActor.newInstance();
    const orientationWidget = vtk.Interaction.Widgets.vtkOrientationMarkerWidget.newInstance({
      actor: axesActor,
      interactor: renderWindow1.getInteractor(),
    });
    orientationWidget.setEnabled(true);
    orientationWidget.setViewportCorner(
      vtk.Interaction.Widgets.vtkOrientationMarkerWidget.Corners.BOTTOM_LEFT
    );
    orientationWidget.setViewportSize(0.15);
    orientationWidget.setMinPixelSize(100);
    orientationWidget.setMaxPixelSize(300);

    // ----------------------------------------------------------
    // 4) Create pipeline objects for mesh1 and mesh2
    // ----------------------------------------------------------
    console.log("Creating pipeline objects (readers, mappers, actors)...");
    const reader1 = vtk.IO.Core.vtkHttpDataSetReader.newInstance({ fetchGzip: true });
    const reader2 = vtk.IO.Core.vtkHttpDataSetReader.newInstance({ fetchGzip: true });

    const mapper1 = vtk.Rendering.Core.vtkMapper.newInstance();
    const actor1 = vtk.Rendering.Core.vtkActor.newInstance();
    actor1.setMapper(mapper1);

    const mapper2 = vtk.Rendering.Core.vtkMapper.newInstance();
    const actor2 = vtk.Rendering.Core.vtkActor.newInstance();
    actor2.setMapper(mapper2);

    // ----------------------------------------------------------
    // 5) Create a viridis-like Color Transfer Function for mesh1
    // ----------------------------------------------------------
    console.log("Setting up Color Transfer Function (viridis-like) for mesh1...");
    const lut = vtk.Rendering.Core.vtkColorTransferFunction.newInstance();
    // Instead of setColorSpaceToDiverging (which is not supported), use:
    lut.setColorSpaceToRGB(); // or remove this line if the default RGB is acceptable
    // Approx viridis control points:
    lut.addRGBPoint(0.0, 0.267, 0.005, 0.329);
    lut.addRGBPoint(0.33, 0.128, 0.568, 0.551);
    lut.addRGBPoint(0.66, 0.369, 0.788, 0.382);
    lut.addRGBPoint(1.0, 0.993, 0.906, 0.144);

    mapper1.setLookupTable(lut);
    mapper1.setColorModeToMapScalars();
    mapper1.setScalarModeToUsePointFieldData();

    // For mesh2, we\u2019ll store direct RGB colors, so:
    mapper2.setScalarModeToUsePointFieldData();
    mapper2.setColorModeToDirectScalars();

    // ----------------------------------------------------------
    // 6) Scalar bar for mesh1
    // ----------------------------------------------------------
    console.log("Adding scalar bar for mesh1...");
    const scalarBarActor = vtk.Rendering.Core.vtkScalarBarActor.newInstance();
    scalarBarActor.setScalarsToColors(lut);
    scalarBarActor.setNumberOfLabels(5);
    scalarBarActor.setTitle('Mesh Scalar');
    // Position in normalized viewport coordinates
    scalarBarActor.setPosition(0.85, 0.05);
    scalarBarActor.setWidth(0.1);
    scalarBarActor.setHeight(0.4);
    renderer1.addActor(scalarBarActor);

    // ----------------------------------------------------------
    // 7) Smoothing function to reduce discrete color steps in mesh2
    // ----------------------------------------------------------
    console.log("Defining smoothing function for mesh2 color array...");
    function smoothColorArray(polyData, colorArray) {
      console.log("  -> smoothColorArray() called");
      const polys = polyData.getPolys().getData();
      const nPoints = polyData.getPoints().getNumberOfPoints();

      const adjacency = new Array(nPoints).fill(null).map(() => []);
      let idx = 0;
      while (idx < polys.length) {
        const nPts = polys[idx++];
        const cellVerts = polys.slice(idx, idx + nPts);
        idx += nPts;
        // build adjacency
        for (let a = 0; a < cellVerts.length; a++) {
          for (let b = a + 1; b < cellVerts.length; b++) {
            adjacency[cellVerts[a]].push(cellVerts[b]);
            adjacency[cellVerts[b]].push(cellVerts[a]);
          }
        }
      }

      const newColor = new Float32Array(colorArray.length);
      for (let v = 0; v < nPoints; v++) {
        const neighbors = adjacency[v];
        neighbors.push(v); // include self
        let r = 0, g = 0, b = 0;
        for (const nb of neighbors) {
          r += colorArray[3 * nb + 0];
          g += colorArray[3 * nb + 1];
          b += colorArray[3 * nb + 2];
        }
        const count = neighbors.length;
        newColor[3 * v + 0] = r / count;
        newColor[3 * v + 1] = g / count;
        newColor[3 * v + 2] = b / count;
      }
      console.log("  -> smoothColorArray() complete");
      return newColor;
    }

    // ----------------------------------------------------------
    // 8) Load JSON data: mesh1, mesh2, T12
    // ----------------------------------------------------------
    // Use your actual JSON file URL (which is publicly accessible)
    const urlOfJson = 'https://oothomas.github.io/assets/data/output_vtk_data.json';

    console.log("Fetching JSON from:", urlOfJson);
    fetch(urlOfJson)
      .then((response) => {
        console.log("  -> JSON fetch status:", response.status, response.statusText);
        return response.json();
      })
      .then((data) => {
        console.log("  -> JSON successfully parsed. Keys in data:", Object.keys(data));

        // data: { mesh1: {...}, mesh2: {...}, vertexMapping: [...] }
        // Convert each mesh object into vtk.js polydata
        console.log("Parsing mesh1 and mesh2...");
        const txtEncoder = new TextEncoder();
        const mesh1DataAB = txtEncoder.encode(JSON.stringify(data.mesh1)).buffer;
        const mesh2DataAB = txtEncoder.encode(JSON.stringify(data.mesh2)).buffer;

        reader1.parseAsArrayBuffer(mesh1DataAB);
        reader2.parseAsArrayBuffer(mesh2DataAB);

        const mesh1PolyData = reader1.getOutputData();
        const mesh2PolyData = reader2.getOutputData();
        console.log("  -> mesh1PolyData points:", mesh1PolyData.getPoints().getNumberOfPoints());
        console.log("  -> mesh2PolyData points:", mesh2PolyData.getPoints().getNumberOfPoints());

        const vertexMapping = data.vertexMapping;
        console.log("  -> vertexMapping length:", vertexMapping.length);

        // (A) Assign scalar array to mesh1
        console.log("Building scalar array for mesh1...");
        const nVerts1 = mesh1PolyData.getPoints().getNumberOfPoints();
        const scalars1 = new Float32Array(nVerts1);
        for (let i = 0; i < nVerts1; i++) {
          scalars1[i] = i / (nVerts1 - 1); // simple 0..1 ramp
        }

        // Store as "Scalars" on mesh1
        console.log("Attaching mesh1_scalars to mesh1...");
        const scalarData1 = vtk.Common.Core.vtkDataArray.newInstance({
          name: 'mesh1_scalars',
          values: scalars1,
          numberOfComponents: 1,
        });
        mesh1PolyData.getPointData().setScalars(scalarData1);

        // (B) Transfer color to mesh2
        console.log("Transferring color from mesh1 to mesh2 using vertexMapping...");
        const nVerts2 = mesh2PolyData.getPoints().getNumberOfPoints();
        const colors2 = new Float32Array(3 * nVerts2);
        const counts2 = new Uint32Array(nVerts2);

        for (let i = 0; i < nVerts1; i++) {
          const mapped = vertexMapping[i];
          if (mapped >= 0 && mapped < nVerts2) {
            const c = lut.getColor(scalars1[i]); // [r, g, b] in [0..1]
            colors2[3 * mapped + 0] += c[0];
            colors2[3 * mapped + 1] += c[1];
            colors2[3 * mapped + 2] += c[2];
            counts2[mapped]++;
          }
        }

        // Average + default to black if no hits
        console.log("Averaging colors in mesh2...");
        for (let v = 0; v < nVerts2; v++) {
          if (counts2[v] > 0) {
            colors2[3 * v + 0] /= counts2[v];
            colors2[3 * v + 1] /= counts2[v];
            colors2[3 * v + 2] /= counts2[v];
          } else {
            colors2[3 * v + 0] = 0.0;
            colors2[3 * v + 1] = 0.0;
            colors2[3 * v + 2] = 0.0;
          }
        }

        // Optional smoothing pass
        console.log("Smoothing mesh2 color array...");
        const smoothedColors2 = smoothColorArray(mesh2PolyData, colors2);

        const colorData2 = vtk.Common.Core.vtkDataArray.newInstance({
          name: 'mesh2_colors',
          values: smoothedColors2,
          numberOfComponents: 3,
        });
        mesh2PolyData.getPointData().setScalars(colorData2);

        // (C) Hook up the polydata to the mappers, add actors to each renderer
        console.log("Setting mapper inputs & adding actors to scene...");
        mapper1.setInputData(mesh1PolyData);
        mapper2.setInputData(mesh2PolyData);
        renderer1.addActor(actor1);
        renderer2.addActor(actor2);

        // Reset cameras & render
        console.log("Resetting camera & rendering...");
        renderer1.resetCamera();
        renderer2.resetCamera();
        renderWindow1.render();
        renderWindow2.render();
        console.log("==== Done! ====");
      })
      .catch((err) => {
        console.error('Failed to load JSON:', err);
      });
  </script>
</body>
</html>
